{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import Input,backend\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../datasets/train_test_data.csv\",\n",
    "                           header=0, parse_dates=[0], index_col=0)\n",
    "\n",
    "#params for generator\n",
    "label_index = len(dataset.columns) -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparamters\n",
    "batch_size=64\n",
    "\n",
    "#params for generator\n",
    "delay=0\n",
    "step=1 # 1 timestep = 1 day\n",
    "lookback=10\n",
    "\n",
    "#ratio for train/val/test split\n",
    "train_ratio=0.7\n",
    "val_ratio=0.15\n",
    "\n",
    "train_max_idx = math.ceil(len(dataset)*train_ratio)\n",
    "val_max_idx = math.ceil(len(dataset)*(train_ratio+val_ratio))\n",
    "\n",
    "# 1 step = 1 batche of samples \n",
    "train_steps = (train_max_idx+1) // batch_size\n",
    "val_steps =  (val_max_idx - train_max_idx - lookback) // batch_size\n",
    "test_steps = (len(dataset) - val_max_idx - lookback) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data, label_index, lookback, delay, min_index, max_index,\n",
    "              shuffle=False, batch_size=64, step=1):\n",
    "    if max_index is None:\n",
    "        max_index = len(data) - delay - 1\n",
    "    i = min_index + lookback\n",
    "    while 1:\n",
    "        if shuffle:\n",
    "            rows = np.random.randint(\n",
    "                min_index + lookback, max_index, size=batch_size)\n",
    "        else:\n",
    "            if i + batch_size >= max_index: \n",
    "                i = min_index + lookback #reset 'i'\n",
    "            rows = np.arange(i, min(i + batch_size, max_index))\n",
    "            i += len(rows)\n",
    "\n",
    "        samples = np.zeros((len(rows),\n",
    "                           lookback // step,\n",
    "                           (data.shape[-1] - 1)))\n",
    "        targets = np.zeros((len(rows),))\n",
    "        for j, row in enumerate(rows):\n",
    "            indices = range(rows[j] - lookback, rows[j], step)\n",
    "            samples[j] = np.delete(data[indices], label_index, axis=1) # an np array without the label col\n",
    "            targets[j] = data[rows[j] + delay][label_index]\n",
    "        yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init generators\n",
    "train_rand_gen = generator(dataset.to_numpy(),\n",
    "                      label_index=label_index,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=train_max_idx,\n",
    "                      shuffle=True,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "\n",
    "train_gen = generator(dataset.to_numpy(),\n",
    "                      label_index=label_index,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=0,\n",
    "                      max_index=train_max_idx,\n",
    "                      shuffle=False,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_gen = generator(dataset.to_numpy(),\n",
    "                    label_index=label_index,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=train_max_idx+1,\n",
    "                      max_index=val_max_idx,\n",
    "                      shuffle=False,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)\n",
    "\n",
    "test_gen = generator(dataset.to_numpy(),\n",
    "                      label_index=label_index,\n",
    "                      lookback=lookback,\n",
    "                      delay=delay,\n",
    "                      min_index=val_max_idx+1,\n",
    "                      max_index=None,\n",
    "                      shuffle=False,\n",
    "                      step=step, \n",
    "                      batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric(y_true, Y_pred):\n",
    "    print('F1 score: %f' % f1_score(y_true, Y_pred))\n",
    "    print('precision score: %f' % precision_score(y_true, Y_pred))\n",
    "    print('recall score: %f' % recall_score(y_true, Y_pred))\n",
    "    print('accuracy score: %f' % accuracy_score(y_true, Y_pred))\n",
    "    print('matthews_corrcoef: %f' % matthews_corrcoef(y_true, Y_pred))\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(confusion_matrix(y_true, Y_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs_to_binary_classes(preds, threshold=0.5):\n",
    "    \"\"\"\n",
    "    preds: np array\n",
    "    threshold: scalar\n",
    "    \"\"\"\n",
    "    return np.where(preds > threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_counts(x):\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    print(np.asarray((unique, counts)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8032      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,065\n",
      "Trainable params: 8,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 0s 8ms/step - loss: 0.5478 - acc: 0.7551\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5308 - acc: 0.7531\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5227 - acc: 0.7485\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5201 - acc: 0.7602\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5101 - acc: 0.7579\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4918 - acc: 0.7720\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4961 - acc: 0.7695\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5081 - acc: 0.7608\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5032 - acc: 0.7590\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4904 - acc: 0.7695\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4898 - acc: 0.7764\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4978 - acc: 0.7705\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4920 - acc: 0.7713\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5044 - acc: 0.7577\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4901 - acc: 0.7789\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4840 - acc: 0.7792\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4963 - acc: 0.7682\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4965 - acc: 0.7595\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4854 - acc: 0.7877\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4859 - acc: 0.7748\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4962 - acc: 0.7695\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4804 - acc: 0.7843\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4769 - acc: 0.7789\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4701 - acc: 0.7838\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4519 - acc: 0.7935\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4661 - acc: 0.7874\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4593 - acc: 0.7918\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4612 - acc: 0.7984\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4672 - acc: 0.7818\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4613 - acc: 0.7853\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4684 - acc: 0.7877\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4373 - acc: 0.8058\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4449 - acc: 0.8015\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4507 - acc: 0.7997\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4479 - acc: 0.7951\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4570 - acc: 0.7920\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4522 - acc: 0.8005\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4515 - acc: 0.8023\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4433 - acc: 0.8025\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4449 - acc: 0.8023\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4458 - acc: 0.7976\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4377 - acc: 0.8087\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4296 - acc: 0.8097\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4351 - acc: 0.8030\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4366 - acc: 0.8064\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4404 - acc: 0.8074\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4350 - acc: 0.8028\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4324 - acc: 0.8122\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4257 - acc: 0.8176\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4296 - acc: 0.8166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f97d53a29b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build s FC model from the book\n",
    "\n",
    "input_shape = (lookback//step, dataset.shape[-1] - 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=input_shape))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "# #fit the model\n",
    "model.fit_generator(train_rand_gen,\n",
    "                    steps_per_epoch=train_steps,\n",
    "                    epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_to_samples_and_targets(generator, steps):\n",
    "    count=0\n",
    "    X, Y = [], []\n",
    "    for samples, targets in generator:\n",
    "        if count >= steps:\n",
    "            break;\n",
    "        else:\n",
    "            count+=1\n",
    "\n",
    "        X.append(samples)\n",
    "        Y.append(targets)\n",
    "\n",
    "    return np.concatenate(X, axis=0), np.concatenate(Y, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2920 neg cases and 984 pos cases from train data\n",
      "the common sense baseline (accuracy score) is 0.7479508196721312\n"
     ]
    }
   ],
   "source": [
    "neg = 2762+158\n",
    "pos = 177+807\n",
    "print(\"We have {0} neg cases and {1} pos cases from train data\".format(neg,pos))\n",
    "print(\"the common sense baseline (accuracy score) is {0}\".format(neg/(pos+neg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.500673\n",
      "precision score: 0.741036\n",
      "recall score: 0.378049\n",
      "accuracy score: 0.809939\n",
      "matthews_corrcoef: 0.432616\n",
      "\n",
      "Confusion matrix:\n",
      "[[2790  130]\n",
      " [ 612  372]]\n"
     ]
    }
   ],
   "source": [
    "#Make predictions for train set\n",
    "    \n",
    "X, Y = generator_to_samples_and_targets(train_gen, train_steps)    \n",
    "Y_pred = model.predict(X)\n",
    "print_metric(Y, probs_to_binary_classes(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.000000\n",
      "precision score: 0.000000\n",
      "recall score: 0.000000\n",
      "accuracy score: 0.985577\n",
      "matthews_corrcoef: -0.004015\n",
      "\n",
      "Confusion matrix:\n",
      "[[820   1]\n",
      " [ 11   0]]\n"
     ]
    }
   ],
   "source": [
    "#Make predictions from dev set\n",
    "X, Y = generator_to_samples_and_targets(val_gen, val_steps)    \n",
    "Y_pred = model.predict(X)\n",
    "print_metric(Y, probs_to_binary_classes(Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.000000\n",
      "precision score: 0.000000\n",
      "recall score: 0.000000\n",
      "accuracy score: 0.963942\n",
      "matthews_corrcoef: 0.000000\n",
      "\n",
      "Confusion matrix:\n",
      "[[802   0]\n",
      " [ 30   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kevin/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/kevin/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:872: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "#Make predictions for test set\n",
    "X, Y = generator_to_samples_and_targets(test_gen, test_steps)    \n",
    "Y_pred = model.predict(X)\n",
    "print_metric(Y, probs_to_binary_classes(Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
