{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "\n",
    "import params\n",
    "from utils.sequence_data import data_to_sequences_and_labels\n",
    "from utils.metrics import print_report_for_binary_classfier\n",
    "from utils.preprocessing import probs_to_binary_classes\n",
    "from utils.hyperparams import hyperparams_search\n",
    "from utils.plot import plot_train_validation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../datasets/data_for_models/dataset_1996-01-01_2019-08-22.csv\",\n",
    "                           header=0, parse_dates=[0], index_col=0)\n",
    "\n",
    "INPUT_SHAPE = (params.LOOKBACK//params.STEP, dataset.shape[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params for generating sequences \n",
    "train_max_idx = math.ceil(len(dataset)*params.TRAIN_RATIO)\n",
    "val_max_idx = math.ceil(len(dataset)*(params.TRAIN_RATIO+params.VAL_RATIO))\n",
    "label_index = len(dataset.columns) -1\n",
    "\n",
    "\n",
    "# prepare data\n",
    "train_X, train_Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK, \n",
    "                                                params.STEP, \n",
    "                                                0, train_max_idx, \n",
    "                                                params.DELAY,\n",
    "                                                label_index) \n",
    "val_X, val_Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK, \n",
    "                                                params.STEP, \n",
    "                                                train_max_idx+1, val_max_idx, \n",
    "                                                params.DELAY,\n",
    "                                                label_index)\n",
    "test_X, test_Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK, \n",
    "                                                params.STEP, \n",
    "                                                val_max_idx+1, None, \n",
    "                                                params.DELAY,\n",
    "                                                label_index)\n",
    "X, Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK,\n",
    "                                   params.STEP,\n",
    "                                   0, val_max_idx,\n",
    "                                   params.DELAY\n",
    "                                   ,label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare for gridsearchCV\n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV \n",
    "cv = TimeSeriesSplit(n_splits=3)\n",
    "matthews_score = make_scorer(matthews_corrcoef, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_model(input_shape, hidden_unit=32, n_layer=2, l2_weight=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    \n",
    "    for _ in range(n_layer):\n",
    "        model.add(Dense(hidden_unit, activation='relu', kernel_regularizer=regularizers.l2(l2_weight)))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda2/envs/py36/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.265330). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    }
   ],
   "source": [
    "fc_params = dict(hidden_unit=[32, 48, 64], \n",
    "                 n_layer=[2,3,4], \n",
    "                 epochs=[100, 250, 500],\n",
    "                 l2_weight=[0,0.0001,0.001, 0.01])\n",
    "\n",
    "fc_clf = GridSearchCV(estimator=KerasClassifier(build_fn=fc_model, input_shape=INPUT_SHAPE, verbose=0),\n",
    "                      param_grid=fc_params,\n",
    "                      cv =cv,\n",
    "                      scoring=matthews_score)\n",
    "grid_result=fc_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best result \n",
    "best_params = {'epochs': 1048, 'n_layer': 3, 'hidden_unti': 32, 'l2_weight': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 2984 positive and 984 negtive cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for train set   \n",
    "print(collections.Counter(train_Y))\n",
    "print_report_for_binary_classfier(train_Y, fc_clf.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Make predictions from dev set\n",
    "print(collections.Counter(val_Y))\n",
    "print_report_for_binary_classfier(val_Y, fc_clf.predict(val_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for test set\n",
    "print(collections.Counter(test_Y))\n",
    "print_report_for_binary_classfier(test_Y, fc_clf.predict(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model.save(params.BEST_FC_MODEL_PATH)  # creates a HDF5 file 'my_model.h5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
