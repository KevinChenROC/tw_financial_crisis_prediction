{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "import params\n",
    "from utils.sequence_data import data_to_sequences_and_labels\n",
    "from utils.metrics import print_report_for_binary_classfier\n",
    "from utils.preprocessing import probs_to_binary_classes\n",
    "from utils.hyperparams import hyperparams_search\n",
    "from utils.plot import plot_train_validation_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../datasets/data_for_models/dataset_1996-01-01_2019-08-22.csv\",\n",
    "                           header=0, parse_dates=[0], index_col=0)\n",
    "\n",
    "input_shape = (params.LOOKBACK//params.STEP, dataset.shape[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params for generating sequences \n",
    "train_max_idx = math.ceil(len(dataset)*params.TRAIN_RATIO)\n",
    "val_max_idx = math.ceil(len(dataset)*(params.TRAIN_RATIO+params.VAL_RATIO))\n",
    "label_index = len(dataset.columns) -1\n",
    "\n",
    "\n",
    "# prepare data\n",
    "train_X, train_Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK, \n",
    "                                                params.STEP, \n",
    "                                                0, train_max_idx, \n",
    "                                                params.DELAY,\n",
    "                                                label_index) \n",
    "val_X, val_Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK, \n",
    "                                                params.STEP, \n",
    "                                                train_max_idx+1, val_max_idx, \n",
    "                                                params.DELAY,\n",
    "                                                label_index)\n",
    "test_X, test_Y = data_to_sequences_and_labels(dataset.to_numpy(), params.LOOKBACK, \n",
    "                                                params.STEP, \n",
    "                                                val_max_idx+1, None, \n",
    "                                                params.DELAY,\n",
    "                                                label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_model(hidden_unit, n_layer, l2_weight, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    \n",
    "    for _ in range(n_layer):\n",
    "        model.add(Dense(hidden_unit, activation='relu', kernel_regularizer=regularizers.l2(l2_weight)))\n",
    "        \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params = hyperparams_search(model_func=fc_model, \n",
    "                                 input_shape=input_shape,\n",
    "                                 train_X=train_X, train_Y=train_Y, \n",
    "                                 val_X=val_X, val_Y=val_Y,\n",
    "                                 num_epoch=2000,\n",
    "                                 hidden_units=[32,64], \n",
    "                                 n_layers=[2,3], \n",
    "                                 l2_weights=[0,0.0001,0.001, 0.01],\n",
    "                                 is_verbose=0)\n",
    "print(\"\\nbest params = {0}\".format(best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# best result \n",
    "best_params = {'epochs': 1048, 'n_layer': 3, 'hidden_unti': 32, 'l2_weight': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_epoch = best_params['epochs'] \n",
    "n_layer= best_params['n_layer'] \n",
    "hidden_unit=best_params['hidden_unti']  \n",
    "l2_weight=best_params['l2_weight']\n",
    "                    \n",
    "\n",
    "model = fc_model(hidden_unit, n_layer, l2_weight, input_shape)\n",
    "\n",
    "# #fit the model\n",
    "history = model.fit(train_X, train_Y,\n",
    "                    validation_data=(val_X, val_Y),\n",
    "                    epochs=num_epoch,\n",
    "                    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_validation_metric(history, 'loss', 'val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 2984 positive and 984 negtive cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Make predictions for train set   \n",
    "print(collections.Counter(train_Y))\n",
    "print_report_for_binary_classfier(train_Y, probs_to_binary_classes(model.predict(train_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make predictions from dev set\n",
    "print(collections.Counter(val_Y))\n",
    "print_report_for_binary_classfier(val_Y, probs_to_binary_classes(model.predict(val_X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions for test set\n",
    "print(collections.Counter(test_Y))\n",
    "print_report_for_binary_classfier(test_Y, probs_to_binary_classes(model.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save(params.BEST_FC_MODEL_PATH)  # creates a HDF5 file 'my_model.h5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
